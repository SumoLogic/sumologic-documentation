---
id: varnish
title: Sumo Logic App for Varnish
sidebar_label: Varnish
description: Allows you to understand how customers are using your product and service to help define future requirements.
---


The Sumo Logic App for Varnish provides dashboards that help you analyze log and metric events generated by Varnish servers. This app allows you to identify traffic sources, monitor and improve application and website workflows, and understand how customers use your product.


#### Sample Log Message
1.gif "image_tooltip")


**Kubernetes:**

```
{
  "timestamp": 1625219282000,
  "log": "187.255.220.191 - - [01/Jul/2021:15:15:53 +0700] "GET /_includes/wp/blog/wp-content/themes/sumologic/style.css HTTP/1.1" 200 33229114 "http://www.greylock.com" "Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_7; en-us) AppleWebKit/533.21.1 (KHTML, like Gecko) Chrome/19.0.1084.30 Safari/536.5""
  "stream": "stdout",
  "time": "2021-07-02T09:21:20.005706219Z"
}
```


**Non-Kubernetes:**

```
187.255.220.191 - - [01/Jul/2021:15:15:53 +0700] "GET /_includes/wp/blog/wp-content/themes/sumologic/sty
```


## Collect Logs and Metrics for Varnish

This page provides instructions for configuring log and metric collection for the Sumo Logic App for Varnish.


#### **Collection Process Overview**

2.gif "image_tooltip")


Configuring log and metric collection for the Varnish App includes the following tasks:

* Step 1: Configure Fields in Sumo Logic.
* Step 2: Configure Collection for Varnish
    * [Collect Logs and Metrics for Non-Kubernetes environments](https://help.sumologic.com/07Sumo-Logic-Apps/24Web_Servers/Varnish/Collect_Varnish_Logs/Collect_Varnish_Logs_and_Metrics_for_Non-Kubernetes_environments).
    * [Collect Logs and Metrics for Kubernetes environments](https://help.sumologic.com/07Sumo-Logic-Apps/24Web_Servers/Varnish/Collect_Varnish_Logs/Collect_Varnish_Logs_and_Metrics_for_Kubernetes_environments).


##### Step 1: Configure Fields in Sumo Logic
3.gif "image_tooltip")


Create the following Fields in Sumo Logic before configuring the collection. This ensures that your logs and metrics are tagged with relevant metadata, which the app dashboards require. For information on setting up fields, see the [Fields](https://help.sumologic.com/Manage/Fields) help page.

If you are using Varnish in a  non-Kubernetes environment, create the fields:

* component
* environment
* cache_system
* cache_cluster
* pod

If you are using Varnish in a Kubernetes environment, create the fields:



* pod_labels_component
* pod_labels_environment
* pod_labels_cache_system
* pod_labels_cache_cluster


##### Step 2: Configure Collection for Varnish
4.gif "image_tooltip")

Instructions below show how to configure Kubernetes and Non-Kubernetes environments.

### Collect Varnish Logs and Metrics for Kubernetes environments

5.png "image_tooltip")
The Sumo Logic App for Varnish has been tested for** **Varnish Version: 6.4.

In a Kubernetes environment, we use the Telegraf Operator, which is packaged with our Kubernetes collection. You can learn more about it[ here](https://help.sumologic.com/03Send-Data/Collect-from-Other-Data-Sources/Collect_Metrics_Using_Telegraf/01_Telegraf_Collection_Architecture). The diagram below illustrates how data is collected from Varnish in a Kubernetes environment. In the architecture shown below, there are four services that make up the metric collection pipeline: Telegraf, Prometheus, Fluentd, and FluentBit.

The first service in the pipeline is Telegraf. Telegraf collects metrics from Varnish. Note that we’re running Telegraf in each pod we want to collect metrics from as a sidecar deployment, for example, Telegraf runs in the same pod as the containers it monitors. Telegraf uses the Varnish input plugin to obtain metrics. (For simplicity, the diagram doesn’t show the input plugins.) The injection of the Telegraf sidecar container is done by the Telegraf Operator. We also have Fluentbit that collects logs written to standard out and forwards them to FluentD, which in turn sends all the logs and metrics data to a Sumo Logic HTTP Source.



Follow the below instructions to set up the metric collection:



1. Configure Metrics Collection
    1. Setup Kubernetes Collection with the Telegraf operator
    2. Add annotations on your Varnish pods
2. Configure Logs Collection
    3. Configure logging in Varnish.
    4. Add labels on your Varnish pods to capture logs from standard output.
    5. Collecting Varnish Logs from a Log file.

**Prerequisites**

It’s assumed that you are using the latest helm chart version. If not, upgrade using the instructions [here](https://github.com/SumoLogic/sumologic-kubernetes-collection/blob/release-v2.0/deploy/docs/v2_migration_doc.md#how-to-upgrade).


#### Step 1 Configure Metrics Collection
7.gif "image_tooltip")


This section explains the steps to collect Varnish metrics from a Kubernetes environment.

In a Kubernetes environment, we use the Telegraf Operator, which is packaged with our Kubernetes collection. You can learn more on this[ here](https://help.sumologic.com/03Send-Data/Collect-from-Other-Data-Sources/Collect_Metrics_Using_Telegraf/01_Telegraf_Collection_Architecture). Follow the steps listed below to collect metrics from a Kubernetes environment:



1. [Setup Kubernetes Collection with the Telegraf Operator.](https://help.sumologic.com/03Send-Data/Collect-from-Other-Data-Sources/Collect_Metrics_Using_Telegraf/03_Install_Telegraf#Install_Telegraf_in_a_Kubernetes_environment)
2. Add annotations on your Varnish pods

On your Varnish Pods, add the following annotations:


```
annotations:
    telegraf.influxdata.com/class: sumologic-prometheus
    prometheus.io/scrape: "true"
    prometheus.io/port: "9273"
    telegraf.influxdata.com/inputs: |+
    [[inputs.varnish]]
   use_sudo = true
   binary = "/usr/bin/varnishstat"
   stats = ["*"]
   [inputs.varnish.tags]
    component="cache"
    environment="dev_CHANGME"
    cache_system="varnish"
    cache_cluster="varnish_on_k8s_CHANGEME"
```


Please enter in values for the following parameters (marked in bold above):



* telegraf.influxdata.com/inputs - This contains the required configuration for the Telegraf varnish Input plugin. Please refer[ to this doc](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/redis) for more information on configuring the Varnish input plugin for Telegraf. Note: As telegraf will be run as a sidecar, the host should always be localhost.
    * In the input plugins section, which is `[[inputs.varnish]]`
        * **binary **-  The default location of the varnish stat binary. Please override as per your configuration.
        * **use_sudo **- If running as a restricted user, prepend sudo for additional access.
        * **stats **- Stats may also be set to ["*"], which will collect all stats. Please see [this doc](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/varnish) for more information on additional parameters for configuring the Varnish input plugin for Telegraf.
    * In the tags section, which is `[inputs.varnish.tags]`
        * **environment **- This is the deployment environment where the Varnish cluster identified by the value of servers resides. For example: dev, prod or qa. While this value is optional we highly recommend setting it.
        * **cache_cluster **- Enter a name to identify this Varnish cluster. This cluster name will be shown in the Sumo Logic dashboards.

Here’s an explanation for additional values set by this configuration that we request you **please do not modify** as they will cause the Sumo Logic apps to not function correctly.



* telegraf.influxdata.com/class: sumologic-prometheus - This instructs the Telegraf operator what output to use. This should not be changed.
* prometheus.io/scrape: "true" - This ensures our Prometheus will scrape the metrics.
* prometheus.io/port: "9273" - This tells prometheus what ports to scrape on. This should not be changed.
* telegraf.influxdata.com/inputs
    * In the tags section i.e.  `[inputs.varnish.tags]`
        * component: “cache” - This value is used by Sumo Logic apps to identify application components.
        * cache_system: “varnish” - This value identifies the web server system.

For all other parameters please see [this doc](https://help.sumologic.com/03Send-Data/Collect-from-Other-Data-Sources/Collect_Metrics_Using_Telegraf/03_Install_Telegraf#Configuring_Telegraf) for more properties that can be configured in the Telegraf agent globally.



1. Sumo Logic Kubernetes collection will automatically start collecting metrics from the pods having the labels and annotations defined in the previous step.
2. Verify metrics in Sumo Logic.


#### Step 2 Configure Logs Collection
8.gif "image_tooltip")


This section explains the steps to collect Varnish logs from a Kubernetes environment.



1. **(Recommended Method) Add labels on your Varnish pods to capture logs from standard output.**

Follow the instructions below to capture Varnish logs from stdout on Kubernetes.



1. Apply following labels to the Varnish pods:

         labels:

```
environment: "prod_CHANGEME"
component: "cache"
cache_system: "varnish"
cache_cluster: "varnish_on_k8s_CHANGEME"
```


Please enter in values for the following parameters (marked in bold above):



* **environment** - This is the deployment environment where the Varnish cluster identified by the value of **servers** resides. For example: dev, prod or qa. While this value is optional we highly recommend setting it.
* **cache_cluster **- Enter a name to identify this Varnish cluster. This cluster name will be shown in the Sumo Logic dashboards.

Here’s an explanation for additional values set by this configuration that we request you **please do not modify** as they will cause the Sumo Logic apps to not function correctly.

* component: “cache” - This value is used by Sumo Logic apps to identify application components.
* cache_system: “varnish” - This value identifies the cache system.

For all other parameters please see [this doc](https://help.sumologic.com/03Send-Data/Collect-from-Other-Data-Sources/Collect_Metrics_Using_Telegraf/03_Install_Telegraf#Configuring_Telegraf) for more properties that can be configured in the Telegraf agent globally.



1. **(Optional) Collecting Varnish Logs from a Log File**

Follow the  steps below to capture Varnish logs from a log file on Kubernetes.



1. Install the Sumo Logic [tailing sidecar operator](https://github.com/SumoLogic/tailing-sidecar/tree/main/operator#deploy-tailing-sidecar-operator).
2. Add the following annotation in addition to the existing annotations.


```
annotations:
  tailing-sidecar: sidecarconfig;<mount>:<path_of_Varnish_log_file>/<Varnish_log_file_name>
```



    Example:


```
annotations:
  tailing-sidecar: sidecarconfig;data: /var/log/varnish/varnishncsa.log

```



1. Make sure that the Varnish pods are running and annotations are applied by using the command: **kubectl describe pod <Varnish_pod_name>**
2. Sumo Logic Kubernetes collection will automatically start collecting logs from the pods having the annotations defined above.
3. Verify logs in Sumo Logic.

3. **Add an FER to normalize the fields in Kubernetes environments.**

Labels created in Kubernetes environments automatically are prefixed with pod_labels. To normalize these for our app to work, we need to create a Field Extraction Rule if not already created for WebServer Application Components. To do so:



1. Go to **Manage Data > Logs > Field Extraction Rules**.
2. Click the + Add button on the top right of the table.
3. The following form appears:


9.png "image_tooltip")




1. Enter the following options:
* **Rule Name**. Enter the name as **App Observability - Cache**.
* **Applied At.** Choose **Ingest Time**
* **Scope**. Select **Specific Data**
* **Scope**: Enter the following keyword search expression:


```
pod_labels_environment=* pod_labels_component=cache pod_labels_cache_cluster=* pod_labels_cache_cluster=

```



* **Parse Expression**.Enter the following parse expression:


```
if (!isEmpty(pod_labels_environment), pod_labels_environment, "") as environment
| pod_labels_component as component
| pod_labels_cache_system as cache_system
| pod_labels_cache_cluster as cache_cluste

```



1. Click **Save** to create the rule.


### Collect Varnish Logs and Metrics for Non-Kubernetes environments

The Sumo Logic App for Varnish has been tested for** **Varnish Version: 6.0.7.

We use the Telegraf operator for Varnish metric collection and Sumo Logic Installed Collector for collecting Varnish logs. The diagram below illustrates the components of the Varnish collection in a non-Kubernetes environment. Telegraf runs on the same system as Varnish, and uses the [Varnish input plugin](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/varnish) to obtain Varnish metrics, and the Sumo Logic output plugin to send the metrics to Sumo Logic. Logs from Varnish on the other hand are sent to a Sumo Logic Local File source.

This section provides instructions for configuring metrics collection for the Sumo Logic App for Varnish. Follow the below instructions to set up the metric collection:

1. Configure Metrics Collection
    1. Configure a Hosted Collector
    2. Configure an HTTP Logs and Metrics Source
    3. Install Telegraf
    4. Configure and start Telegraf
2. Configure Logs Collection
    5. Configure logging in Varnish
    6. Configure Sumo Logic Installed Collector


#### Step 1 Configure Metrics Collection
12.gif "image_tooltip")




1. **Configure a Hosted Collector** To create a new Sumo Logic hosted collector, perform the steps in the[ Create a Hosted Collector](https://help.sumologic.com/03Send-Data/Hosted-Collectors/Configure-a-Hosted-Collector) section of the Sumo Logic documentation.
2. **Configure an HTTP Logs and Metrics Source** Create a new HTTP Logs and Metrics Source in the hosted collector created above by following[ these instructions. ](https://help.sumologic.com/03Send-Data/Sources/02Sources-for-Hosted-Collectors/HTTP-Source)Make a note of the **HTTP Source URL**.
3. **Install Telegraf** Use the[ following steps](https://help.sumologic.com/03Send-Data/Collect-from-Other-Data-Sources/Collect_Metrics_Using_Telegraf/03_Install_Telegraf) to install Telegraf.
4. **Configure and start Telegraf** As part of collecting metrics data from Telegraf, we will use the [Varnish input plugin](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/varnish) to get data from Telegraf and the [Sumo Logic output plugin](https://github.com/SumoLogic/fluentd-output-sumologic) to send data to Sumo Logic.  \
 \
Create or modify telegraf.conf and copy and paste the text below:  


```
 use_sudo = true
  binary = "/usr/bin/varnishstat"
  stats = ["*"]
  [inputs.varnish.tags]
   component="cache"
   environment="dev_CHANGME"
   cache_system="varnish"
   cache_cluster="varnish_on_premise_CHANGEME"

  url = "<URL Created in Step 3_CHANGEME>"
  data_format = "prometheus"
```


Please enter values for the following parameters (marked in **bold** above):


* In the input plugins section, which is `[[inputs.varnish]]`
    * **binary** -  The default location of the varnish stat binary. Please override as per your configuration.
    * **use_sudo - If running as a restricted user, prepend sudo for additional access.**
    * **stats** - Stats may also be set to ["*"], which will collect all stats. Please see [this doc](https://github.com/influxdata/telegraf/tree/master/plugins/inputs/varnish) for more information on additional parameters for configuring the Varnish input plugin for Telegraf.
    * In the tags section, which is `[inputs.varnish.tags]`
        * **environment** - This is the deployment environment where the Varnish cluster identified by the value of **servers** resides. For example; dev, prod or qa. While this value is optional we highly recommend setting it.
        * **cache_cluster **- Enter a name to identify this Varnish cluster. This cluster name will be shown in the Sumo Logic dashboards.
* In the output plugins section, which is `[[outputs.sumologic]]`
    * **url** - This is the HTTP source URL created in step 3. Please see [this doc](https://help.smologic.com/03Send-Data/Collect-from-Other-Data-Sources/Collect_Metrics_Using_Telegraf/05_Configure_Telegraf_Output_Plugin_for_Sumo_Logic) for more information on additional parameters for configuring the Sumo Logic Telegraf output plugin.

Here’s an explanation for additional values set by this Telegraf configuration that we request you **please do not modify** as they will cause the Sumo Logic apps to not function correctly.


* **data_format** - “`prometheus`” In the output plugins section, which is `[[outputs.sumologic]]`. Metrics are sent in the Prometheus format to Sumo Logic
* **Component**: “`cache`” - In the input plugins section, which is, `[[inputs.varnish]]` - This value is used by Sumo Logic apps to identify application components.

* **cache_system**: “`varnish`” - In the input plugins sections. In other words, this value identifies the cache system
*  For all other parameters please see [this doc](https://github.com/influxdata/telegraf/blob/master/etc/telegraf.conf) for more properties that can be configured in the Telegraf agent globally.

Once you have finalized your `telegraf.conf` file, you can start or reload the telegraf service using instructions from the [doc](https://docs.influxdata.com/telegraf/v1.17/introduction/getting-started/#start-telegraf-service).

At this point, Varnish metrics should start flowing into Sumo Logic.


#### Step 2 Configure Logs Collection
13.gif "image_tooltip")


This section provides instructions for configuring log collection for Varnish running on a non-kubernetes environment for the Sumo Logic App for Varnish.

By default, Varnish logs are stored in a log file. Sumo Logic supports collecting logs via a local log file. Local log files can be collected via [Installed collectors](https://help.sumologic.com/03Send-Data/Installed-Collectors). An Installed collector will require you to allow outbound traffic to [Sumo Logic endpoints](https://help.sumologic.com/APIs/General-API-Information/Sumo-Logic-Endpoints-and-Firewall-Security) for collection to work. For detailed requirements for Installed collectors, see this [page](https://help.sumologic.com/01Start-Here/03About-Sumo-Logic/System-Requirements/Installed-Collector-Requirements).





1. Configure logging in Varnish \
Varnish supports logging via the following methods: local text log files. For details please visit this [page](https://docs.varnish-software.com/tutorials/enabling-logging-with-varnishncsa/). \
For the dashboards to work properly, please set the below specified log format as explained [here](https://docs.varnish-software.com/tutorials/enabling-logging-with-varnishncsa/#step-3-customise-options-1):  \
`%h %l %u %t \"%r\" %s %b \"%{Referer}i\" \"%{User-agent}i\"`
2. Configure Varnish to log to a Local file \
By default any installation of varnishd will not write any request logs to disk. Instead  \
Varnish has an in-memory log, and supplies tools to tap into this log and write to disk. To  \
configure logging to a local file, follow the steps on [this](https://docs.varnish-software.com/tutorials/enabling-logging-with-varnishncsa/#enable-varnishncsa-logging) page. \
By default, Varnish logs are stored in **/var/log/varnish/varnishncsa.log**. For customized options please visit this [page](https://docs.varnish-software.com/tutorials/enabling-logging-with-varnishncsa/#step-3-customise-options-1). \
Logs from the Varnish log file can be collected via a Sumo Logic [Installed collector](https://help.sumologic.com/03Send-Data/Installed-Collectors) and a [Local File Source](https://help.sumologic.com/03Send-Data/Sources/01Sources-for-Installed-Collectors/Local-File-Source) as explained in the next section.
3. Configuring a Collector \
To add an Installed collector, perform the steps as defined on the page[ Configure an Installed Collector.](https://help.sumologic.com/03Send-Data/Installed-Collectors)
4. Configuring a Source \
**To add a Local File Source source for Varnish do the following \
**To collect logs directly from your Varnish machine, use an Installed Collector and a Local File Source.  
    1. Add a[ Local File Source](https://help.sumologic.com/03Send-Data/Sources/01Sources-for-Installed-Collectors/Local-File-Source).
    2. Configure the Local File Source fields as follows:
* **Name.** (Required)
* **Description.** (Optional)
* **File Path (Required).** Enter the path to your error.log or access.log. The files are typically located in **/var/log/varnish/varnishncsa.log**.
* **Source Host.** Sumo Logic uses the hostname assigned by the OS unless you enter a different host name
* **Source Category.** Enter any string to tag the output collected from this Source, such as **Varnish/Logs**. (The Source Category metadata field is a fundamental building block to organize and label Sources. For details see[ Best Practices](https://help.sumologic.com/03Send-Data/01-Design-Your-Deployment/Best-Practices:-Good-Source-Category,-Bad-Source-Category).)

    **Fields. **Set the following fields:

* `component = cache`
* `cache_system = varnish`
* `cache_cluster = <Your_Varnish_Cluster_Name>`
* `environment = <Environment_Name>`, such as Dev, QA or Prod.

1. Configure the **Advanced** section:
* **Enable Timestamp Parsing.** Select Extract timestamp information from log file entries.
* **Time Zone.** Choose the option, **Ignore time zone from log file and instead use**, and then select your Varnish Server’s time zone.
* **Timestamp Format.** The timestamp format is automatically detected.
* **Encoding. **Select** **UTF-8 (Default).
* **Enable Multiline Processing.** Detect messages spanning multiple lines
    * Infer Boundaries - Detect message boundaries automatically
1. Click **Save**. \
At this point, Varnish logs should start flowing into Sumo Logic.


## Varnish Alerts

Sumo Logic has provided out-of-the-box alerts available via[ Sumo Logic monitors](https://help.sumologic.com/Visualizations-and-Alerts/Alerts/Monitors) to help you quickly determine if the Varnish cache is available and performing as expected.


<table>
  <tr>
   <td>Alert Type (Metrics/Logs)
   </td>
   <td>Alert Name
   </td>
   <td>Alert Description
   </td>
   <td>Trigger Type (Critical / Warning)
   </td>
   <td>Alert Condition
   </td>
   <td>Recover Condition
   </td>
  </tr>
  <tr>
   <td>Metrics
   </td>
   <td>Varnish - Backend Busy
   </td>
   <td>This alert fires when the Varnish backend is busy for more than 5 minutes and is unable to serve requests.
   </td>
   <td>Warning
   </td>
   <td> &#62;0
   </td>
   <td> &#60; &#61;0
   </td>
  </tr>
  <tr>
   <td>Metrics
   </td>
   <td>Varnish - Backend Connection Retries
   </td>
   <td>This alert fires when there a more than 5 backend connection retries, which can indicate misconfiguration.
   </td>
   <td>Warning
   </td>
   <td> &#62;5
   </td>
   <td> &#60; &#61;5
   </td>
  </tr>
  <tr>
   <td>Metrics
   </td>
   <td>Varnish - Backend Failed Connections
   </td>
   <td>This alert fires when there are failed connections to the backend.
   </td>
   <td>Warning
   </td>
   <td> &#62;0
   </td>
   <td> &#60; &#61;0
   </td>
  </tr>
  <tr>
   <td>Metrics
   </td>
   <td>Varnish - Unhealthy Backend
   </td>
   <td>This alert fires when we detect that a backend server is unhealthy for more than 5 minutes.
   </td>
   <td>Critical
   </td>
   <td> &#62;0
   </td>
   <td> &#60; &#61;0
   </td>
  </tr>
  <tr>
   <td>Metrics
   </td>
   <td>Varnish - Thread creation failed
   </td>
   <td>This alert fires when Varnish is unable to create threads, which indicates either under-provisioning or misconfiguration.
   </td>
   <td>Warning
   </td>
   <td> &#62;0
   </td>
   <td> &#60; &#61;0
   </td>
  </tr>
  <tr>
   <td>Logs
   </td>
   <td>Varnish - Access from Highly Malicious Sources
   </td>
   <td>This alert fires when Varnish is accessed from highly malicious IP addresses.
   </td>
   <td>Critical
   </td>
   <td> &#62;0
   </td>
   <td> &#60; &#61;0
   </td>
  </tr>
  <tr>
   <td>Logs
   </td>
   <td>Varnish - High 4XX Error Rate
   </td>
   <td>This alert fires when too many HTTP requests (>5%) with a response status of 4xx.
   </td>
   <td>Critical
   </td>
   <td> &#62;5
   </td>
   <td> &#60; &#61;5
   </td>
  </tr>
  <tr>
   <td>Logs
   </td>
   <td>Varnish - High 5XX Error Rate
   </td>
   <td>This alert fires when too many HTTP requests (>5%) with a response status of 5xx.
   </td>
   <td>Critical
   </td>
   <td> &#62;5
   </td>
   <td> &#60; &#61;5
   </td>
  </tr>
</table>
