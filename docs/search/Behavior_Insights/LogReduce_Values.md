---
id: logreduce-values
---

# LogReduce Values

TheÂ ****LogReduce Values****Â operator allows you to quickly explore
structuredÂ logs by knownÂ keys.Â Structured logs can be inÂ JSON, CSV,
key-value, or any structured format. Unlike the LogReduce Keys operator,
you need to specify the keys you want to explore. The values of each
specified key are parsed and aggregated for you to explore.

This operator does not automatically
[parse](../Search-Query-Language/01-Parse-Operators.md "Parse Operators")
yourÂ logs. You need to parse the keysÂ you want to explore prior to
specifying them in the LogReduce Values operation.Â 

The following table shows the fields that are returned in results.

[TABLE]

With the provided results you can:

-   Click the provided links to drill down and further explore
    logsÂ fromÂ each schema.
-   Compare results against a previous time range
    withÂ [LogCompare](../LogCompare.md "LogCompare").
-   Run subsequent searches.

### Syntax

`| logreduce values on\<key\>[,\<key\>, ...] [output_threshold\<output_threshol\>]`

[TABLE]

#### Details option

The details optionÂ allows you to investigate and manipulateÂ logs from
specific data clusters generated by a previously run LogReduce Values
search.

There are two methods you have to use the details option:

-   Click on theÂ **\_count**Â field value from theÂ LogReduce Values
    search results.  
    ![details option by
    link.png](../static/img/Behavior_Insights/LogReduce_Values/details%20option%20by%20link.png)  
      
    A new searchÂ is created with the necessary identifiers from your
    initial LogReduce Values search. The search contains all of the raw
    logs from the selected data cluster.  
    Â 
-   Manually provide the necessary identifiers. You can provide
    identifiers from previously run LogReduce Values searches.Â However,
    the only way to get the search identifier, given with
    theÂ `shortcodeID`Â parameter, is to click theÂ **\_count**Â link from
    the interface. The query of the created search has the identifier
    that you can save for later use, up to 1,095 days. For example, the
    following query was created by clicking theÂ **\_count**Â link:  
      
    `| logreduce values details on %"region", %"partition" pCV6qgaOvASgi1j9KhcGaE6mts6jfOEk "C049BE180425642A"`  
      
    TheÂ `pCV6qgaOvASgi1j9KhcGaE6mts6jfOEk`Â value is theÂ `shortcodeID`.
    WhileÂ `C049BE180425642A`Â is aÂ `cluster_id`.

##### Details Syntax

`| logreduce values details on %\<key\>"[, %\<key\>", ...]Â\<shortcodeI\> \<cluster_id\>,\<cluster_id\>, ...]`

| Parameter   | Description                                                                           | Default |
|-------------|---------------------------------------------------------------------------------------|---------|
| keys        | Comma separated list ofÂ keys that were parsed from structured data.                   | Null    |
| cluster_id  | TheÂ signature identifier that was provided from your initial LogReduce Values search. | Null    |
| shortcodeID | The unique hash value assigned to the initial LogReduceÂ Values search.Â                | Null    |

For example, to see details from a particular LogReduce Values search
and data clusters, you'd useÂ the following syntax:Â 

`| logreduce values detailsÂ on %\<key\>"[, %\<key\>", ...]Â\<shortcodeI\> \<cluster_id\>,\<cluster_id\>, ...]`

To see all theÂ logs byÂ cluster identifiersÂ for further processing,
you'dÂ use the following syntax:

`| logreduce values details on %\<key\>"[, %\<key\>", ...]\<shortcodeI\>`

### Limitations

-   Not supported with [Real Time
    alerts](../../Visualizations-and-Alerts/Alerts/Scheduled-Searches/Create_a_Real_Time_Alert.md "Create a Real Time Alert").
-   [Time Compare](../Time-Compare.md "Time Compare") and the [compare
    operator](../Search-Query-Language/Search-Operators/Compare.md "Compare")
    are not supported against LogReduce Values results.
-   If you reach the memory limit you can try to shortenÂ the time range
    or the number of specified fields. When the memory limit is
    reachedÂ you will getÂ partial results on a subset of your data.
-   Response fieldsÂ `_cluster_id`, `_signature`, and `_count`Â are not
    supported with [Dashboard
    filters](../../Visualizations-and-Alerts/Dashboards/Use-Time-Ranges-and-Filters/05Use-Filters-in-Dashboards.md "Use Filters in Dashboards").

##### \_count linkÂ 

-   Searches opened by clicking the linkÂ provided in
    theÂ `_count`Â response field:
    -   are run againstÂ [message
        time](../Get-Started-with-Search/Search-Basics/Built-in-Metadata.md "Built-in Metadata").
    -   can return different results due to variations in your data.
-   WhenÂ provided in a Scheduled Search alert, the link from the
    `_count`Â response fieldÂ is invalid and will not work.

### Examples

##### AWS CloudTrail

In this example, the user wants to cluster AWS CloudTrail logs to
understand errorCodes, likeÂ "AccessDenied", eventSource, likeÂ Ec2 or
S3,Â and eventName. This can reveal patterns such asÂ certain eventSources
contributing more errors than others.

`_sourceCategory= *cloudtrail* errorCode | json field=_raw "eventSource" as eventSource | json field=_raw "eventName" as eventName | json field=_raw "errorCode" as errorCode | logreduce values on eventSource, eventName, errorCode`

##### Kubernetes

After using [LogReduce KeysÂ to scan yourÂ logs for
schemas](LogReduce_Keys.md "LogReduce Keys")Â you can use LogReduce
Values to explore them further based on specific keys.

`_sourceCategory="primary-eks/events" | where _raw contains "forge" | json auto "object.reason", "object.involvedObject.name", "object.message", "object.involvedobject.kind", "object.source.component", "object.metadata.namespace" as reason, objectName, message, kind, component, namespace | logreduce values on reason, objectName, message, kind, component, namespace`

Next, use [LogExplain to determine how frequently
yourÂ `reason`Â isÂ ](LogExplain.md "LogExplain")`FailedScheduling`.Â Â 

##### AWS CloudTrail

The following query helps youÂ see which groups of users, IP addresses,
AWS regions, and S3 event names are prevalent in your AWS CloudTrail
logs that reference AccessDenied errors for AWS.Â Knowing these clusters
can help plan remediation efforts.

`_sourceCategory=*cloudtrail* *AccessDenied* | json field=_raw "userIdentity.userName" as userName nodrop | json field=_raw "userIdentity.sessionContext.sessionIssuer.userName" as userName_role nodrop | if (isNull(userName), if(!isNull(userName_role),userName_role, "Null_UserName"), userName) as userNameÂ  | json field=_raw "eventSource" as eventSource | json field=_raw "eventName" as eventName | json field=_raw "awsRegion" as awsRegion | json field=_raw "errorCode" as errorCode nodrop | json field=_raw "errorMessage" as errorMessage nodrop | json field=_raw "sourceIPAddress" as sourceIp nodrop | json field=_raw "recipientAccountId" as accountId | json field=_raw "requestParameters.bucketName" as bucketName nodrop | where errorCode matches "*AccessDenied*" and eventSource matches "s3.amazonaws.com" Â and accountId matches "*" | logreduce values on eventName, userName, sourceIp, awsRegion, bucketName | sort _count desc`

Results show each uniqueÂ signature:

![CloudTrail example LogReduce
Values.png](../static/img/Behavior_Insights/LogReduce_Values/CloudTrail%20example%20LogReduce%20Values.png)

Next, use [LogExplain](LogExplain.md "LogExplain")Â to analyze which
users, IP addresses, AWS regions, and S3 event names most explain the S3
Access Denied error based on their prevalence in AWS CloudTrail logs
that contain S3 Access Denied errors versus logs that do not contain
these errors.
\<div style="display:none;\>

**Drill down**

If the user wants to drill down on a particular logreduce values query
id and cluster id, we provide a link that leads to the following query.Â 

`_sourceCategory="aws/cloudtrail/production" and _collector="AWS" | json "eventName", "eventSource", "awsRegion", "userAgent", "userIdentity.type", "managementEvent", "readOnly" | logreduce values-details\<shortcodeI\> [clusterId\<cluster i\>]`

If the user wants to label the raw logs by their cluster ids for further
processing, they can use the following query:

`_sourceCategory="aws/cloudtrail/production" and _collector="AWS" | json "eventName", "eventSource", "awsRegion", "userAgent", "userIdentity.type", "managementEvent", "readOnly" | logreduce values-details\<shortcodeI\> | ...`

**Parameters to the logreduce values-details operator:Â **

-   â€˜shortcode_idâ€, required: this is used to link to the serialized
    histograms and fetches them. Once fetched, they are used to
    recluster the logs in the same query and match them to their
    respective clustersÂ 

&nbsp;

-   â€œcluster_labelâ€, optional: The cluster label is passed as a query
    parameter to the logreduce values-details operator which can take
    either a list of labels as a parameter where it only matches the
    logs against the histograms of those labels or no labels where we
    return all logs with a new field which is the cluster label, on
    which we can run the future logexplain operator downstream. Only for
    drilling down, we would pass the cluster label to this operator
    which would return non-agg output of all logs with that cluster
    label.

**Drill down output:**

Non-agg output, with the same schema as the input format, but added an
extra â€œclusterâ€ column which denotes cluster membership.
\</di\>
